{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudiptiwari/ai_school_2023/blob/main/Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae85ce9",
      "metadata": {
        "id": "aae85ce9"
      },
      "source": [
        "# Exercise 1 \n",
        "- Simulate the position of dart throws by two players using the following criteria:\n",
        "    - Player 1: mean x, y position = (0, 0), cov matrix = [[1, 0]  [0, 2]]\n",
        "    - Player 2: mean x, y position = (2, 1), cov matrix = [[3, -2], [-2, 2]]\n",
        "- Draw contourplot displaying the joint probability distributions\n",
        "- Generate 200 samples each for both players and plot those -> use `numpy.random.choice`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules\n",
        "import numpy as np\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "uLH1nd-vFvU_"
      },
      "id": "uLH1nd-vFvU_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Player 1\n",
        "mean = (0, 0)\n",
        "cov = [[1, 0],[0, 2]]\n",
        "p = np.random.multivariate_normal(mean, cov, [2,800])\n",
        "a = p.shape\n",
        "p, p.shape\n",
        "z= stats.multivariate_normal(mean, cov, [2,800])"
      ],
      "metadata": {
        "id": "wiZ6iYYvHUW4"
      },
      "id": "wiZ6iYYvHUW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Player 2\n",
        "mean = (2, 1)\n",
        "cov =  [[3, -2],[-2, 2]]\n",
        "q = np.random.multivariate_normal(mean, cov, [2, 800])\n",
        "q\n",
        "s= stats.multivariate_normal(mean, cov, [2, 800])"
      ],
      "metadata": {
        "id": "rec4_5TdH5tt"
      },
      "id": "rec4_5TdH5tt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b58ca66",
      "metadata": {
        "id": "3b58ca66"
      },
      "source": [
        "# Exercise 2 \n",
        "- Label points from player 1 as `0` and points from player 2 as `1`. \n",
        "- Use `logistic regression` from scipy to classify these points.\n",
        "    - Check performance using `accuracy_score` from `sklearn.metrics`. \n",
        "- Implement your own logistic regression by filling out the functions in the skeleton below.\n",
        "    - Discover tricks to make this converge faster. \n",
        "- Implement the gradient function using:\n",
        "    - The direct method - find out the actual function [from the lecture slides](https://docs.google.com/presentation/d/1fnftEMoecsjflXaIkFUSDcbVg2ksqd9EiOOCC-UwPkU/edit?usp=sharing): \n",
        "    - Numeric/analytical method by computing numeric gradients (if you've already implemented using the direct method above, then just do numeric)\n",
        "- Use any other ML method to achieve better performance - SVM, Neural Networks, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0511cc0e",
      "metadata": {
        "id": "0511cc0e"
      },
      "outputs": [],
      "source": [
        "# fill this out\n",
        "\n",
        "class LogisticRegressionCustom:\n",
        "    \"\"\"\n",
        "    Implement the functions that have pass written.\n",
        "    \"\"\"\n",
        "    T = 1e5\n",
        "    \n",
        "    def get_prob(self, X, beta):                            \n",
        "        pass\n",
        "\n",
        "    def loss(self, X, beta, y):\n",
        "        pass\n",
        "    \n",
        "    def gradient(self, X, beta, y):\n",
        "        pass\n",
        "    \n",
        "    def gradient_descent_fit(self, X, beta, y):\n",
        "        count = 0\n",
        "        beta_ = np.copy(beta)\n",
        "        while count < self.T:\n",
        "            count += 1\n",
        "            grad = self.gradient(X, beta_, y)\n",
        "            beta_ -= LR * grad\n",
        "            if np.sum(np.abs(grad)) < thresh:\n",
        "                break\n",
        "        return beta_\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.beta = np.zeros((X.shape[1] + 1))\n",
        "        self.beta += rng.randn(X.shape[1] + 1)\n",
        "        intercept_X = np.ones((X.shape[0], 1))\n",
        "        self.X = np.concatenate((intercept_X, X), axis=1)\n",
        "        self.y = y\n",
        "        \n",
        "        fitted_beta = self.grad_descent_fit(\n",
        "            self.X, self.beta, self.y\n",
        "        )\n",
        "        self.beta = fitted_beta\n",
        "        return self.beta\n",
        "    \n",
        "    def predict(self, X):\n",
        "        pass\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}